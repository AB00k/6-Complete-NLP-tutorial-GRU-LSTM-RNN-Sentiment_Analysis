{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9Vm1qteVoQ9"
      },
      "source": [
        "###### Some of the content of this homework is adapted from [ LSTM with Pytorch](https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_lstm_neuralnetwork/)\n",
        "\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "<h1><span style=\"color:green\"> EE512: Machine Learning </span><h1>\n",
        "<h2><span style=\"color:green\"> Homework-4 </span><h2>\n",
        "</div>\n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhLr4lNpYPH3"
      },
      "source": [
        "## Recurrent Neural Network(RNN)\n",
        "**Recurrent Neural Networks(RNNs)** are a type of neural network where the **output from previous step is fed as input to the current step.** RNNs are used to tackle problems that requires knowledge from the past to make a prediction such as predicting next word in a sentence. RNN does this by maintaing a \"memory\" through a vector called **Hidden State**.\n",
        "\n",
        " At each time step $t$, an instance of a sequence $x_t\\in\\mathbb{R}^D$ and previous hidden state $h_{t-1}\\in\\mathbb{R}^H$  are passed to RNN. Using these two inputs, hidden state $h_t$ gets updated. The learnable parameters of the RNN are $(W_x\\in\\mathbb{R}^{H\\times D}, W_h\\in\\mathbb{R}^{H\\times H},b\\in\\mathbb{R}^{H} )$  input-to-hidden matrix , a hidden-to-hidden matrix  and a bias vector respectively.\n",
        "\n",
        "$$ h_t = tanh(W_{x}x_t + W_{h}h_{_{t-1}}+b) $$\n",
        "\n",
        "\n",
        "![RNN_folded_unfolded.png](attachment:RNN_folded_unfolded.png)\n",
        "<center>A folded (left) and un-folded (right) version of an RNN. <b>A</b> is feed forward neural network followed by an activation function. </center> \n",
        "\n",
        "<center> <a href=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/\" title=\"colah's blog\">\n",
        "Image Source</a></center>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1AcpBsi6AxzK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J78utjhoVoRD"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<h1><span style=\"color:green\"> Task-1 : Implement One Fully-Connected Layer using nn.Linear  </span></h1>\n",
        "</div>\n",
        "\n",
        "Input row-vector is $x=[1,2,3]$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ilp0z6oVoRD",
        "outputId": "9fc828ad-5a4d-4b6b-a6e3-308b383d1d86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension of Input        :  torch.Size([3])\n",
            "Dimension of Output       :  torch.Size([24])\n",
            "Dimension of Weight Matrix:  torch.Size([24, 3])\n",
            "Dimension of Bias Vector  :  torch.Size([24])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Weight Matrix of Fully-Connected Layer:\n",
            " tensor([[ 0.0620, -0.2227,  0.2560],\n",
            "        [ 0.4110,  0.2781,  0.5542],\n",
            "        [ 0.0268, -0.4913, -0.2040],\n",
            "        [-0.2326, -0.2051, -0.5239],\n",
            "        [ 0.0988, -0.0739, -0.1083],\n",
            "        [ 0.3112, -0.0467, -0.2634],\n",
            "        [-0.5627, -0.0148, -0.3369],\n",
            "        [-0.0025,  0.2711,  0.2552],\n",
            "        [-0.1124, -0.1506, -0.4798],\n",
            "        [-0.0821,  0.5672,  0.0552],\n",
            "        [-0.3041, -0.0383,  0.2553],\n",
            "        [-0.3990,  0.4771, -0.4966],\n",
            "        [-0.2871, -0.1807,  0.3783],\n",
            "        [ 0.3518,  0.4003,  0.0272],\n",
            "        [ 0.1394, -0.2831, -0.4631],\n",
            "        [ 0.3804, -0.3814,  0.1181],\n",
            "        [-0.5648,  0.5569, -0.0754],\n",
            "        [-0.0027,  0.4436, -0.2137],\n",
            "        [ 0.3736, -0.5466, -0.3141],\n",
            "        [ 0.2314,  0.2771,  0.4165],\n",
            "        [-0.3393,  0.2019,  0.4483],\n",
            "        [ 0.2523,  0.0174, -0.2820],\n",
            "        [ 0.3517, -0.1820, -0.1328],\n",
            "        [-0.2073, -0.0258, -0.5399]])\n",
            "\n",
            "\n",
            "\n",
            "Bias Vecotr of Fully-Connected Layer:\n",
            " tensor([ 0.5222, -0.3664,  0.2329,  0.0903,  0.4774, -0.5686,  0.4389,  0.0110,\n",
            "         0.2192, -0.1145, -0.1481,  0.3770, -0.4929,  0.1047, -0.2222,  0.5052,\n",
            "         0.1887, -0.0416, -0.4453, -0.1034,  0.5527,  0.2893,  0.0750, -0.3800])\n",
            "\n",
            "\n",
            "\n",
            "Output:\n",
            " tensor([ 0.9068,  2.2635, -1.3348, -2.1244,  0.1036, -1.1411, -1.1642,  1.3164,\n",
            "        -1.6339,  1.1033,  0.2372, -0.5576, -0.0065,  1.3387, -2.0384,  0.4771,\n",
            "         0.5114,  0.2017, -2.1071,  1.9319,  1.9622, -0.2696, -0.3355, -2.2587],\n",
            "       grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "x = torch.FloatTensor([1,2,3])\n",
        "\n",
        "fc_layer = nn.Linear(3, 4*6)\n",
        "\n",
        "output = fc_layer(x)\n",
        "\n",
        "w = None\n",
        "b = None\n",
        "for name, param in fc_layer.named_parameters():\n",
        "    if name == 'weight':\n",
        "        w = param.data\n",
        "    elif name == 'bias':\n",
        "        b = param.data\n",
        "\n",
        "print('Dimension of Input        : ' , x.shape) # we can also print dementions x.ndimension()\n",
        "print('Dimension of Output       : ' , output.shape)\n",
        "print('Dimension of Weight Matrix: ',w.shape )\n",
        "print('Dimension of Bias Vector  : ' ,b.shape)\n",
        "\n",
        "print('\\n\\n\\n')\n",
        "print('Weight Matrix of Fully-Connected Layer:\\n',w)\n",
        "print('\\n\\n\\nBias Vecotr of Fully-Connected Layer:\\n',b)\n",
        "print('\\n\\n\\nOutput:\\n',output)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 3\n",
        "hidden_dim = 6\n",
        "input = torch.FloatTensor([3,4,5,6])\n",
        "hidden = torch.zeros((1,hidden_dim))"
      ],
      "metadata": {
        "id": "kF8aGU1tMFEh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W_x = nn.Linear(input_dim, 4 * hidden_dim, bias=True)\n",
        "W_h = nn.Linear(hidden_dim, 4 * hidden_dim, bias=True)"
      ],
      "metadata": {
        "id": "FcuhKxXbJLoB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in W_x.named_parameters():\n",
        "    if name == 'weight':\n",
        "        w = param.data\n",
        "    elif name == 'bias':\n",
        "        b = param.data\n",
        "w.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8K_7h5yyiik",
        "outputId": "5c966bc6-6e27-4579-d52b-50d6e9a95344"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([24, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W_x(input).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "5hVnoO_GzD9-",
        "outputId": "b6c4ad5e-2436-4f9f-e55c-cb25bbdf9a1c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-4e676f0d4690>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mW_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x4 and 3x24)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "activation = W_x(input) + W_h(hidden)\n",
        "activation.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPb1sa9HMPrO",
        "outputId": "00e3505a-2601-49c4-d841-dd928dcb0f52"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 24])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "activation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wr_yIBJVNhJo",
        "outputId": "ca8ab4a6-1b7a-4cb1-f556-89be515f3d3e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1789, -3.7217,  3.4697,  0.6477, -0.0525, -4.2697,  0.9152, -5.4598,\n",
              "          1.1937, -1.9445,  5.2034, -1.4306, -0.8855, -0.5019,  3.5420,  2.5287,\n",
              "         -2.1952,  0.7701, -1.2765, -0.1209, -1.8376,  0.1420,  2.4654, -0.0465]],\n",
              "       grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a, b, c, d = activation.chunk(4, dim=1)"
      ],
      "metadata": {
        "id": "58vZEJOcNmGc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'shape of a is {a.shape}')\n",
        "print(f'shape of b is {b.shape}')\n",
        "print(f'shape of c is {c.shape}')\n",
        "print(f'shape of d is {d.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYMnngStOCJ1",
        "outputId": "e875ecdc-e63d-459d-a4fc-6f85717ab365"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of a is torch.Size([1, 6])\n",
            "shape of b is torch.Size([1, 6])\n",
            "shape of c is torch.Size([1, 6])\n",
            "shape of d is torch.Size([1, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdnKEeIpOj4K",
        "outputId": "9209f307-2cc2-4d7b-e3b2-90384c503e0c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1789, -3.7217,  3.4697,  0.6477, -0.0525, -4.2697]],\n",
              "       grad_fn=<SplitBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a1, b1, c1, d1 = activation[:,0:6], activation[:,6:12], activation[:,12:18], activation[:,18:24]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPVJesJKOmrL",
        "outputId": "07167fae-4ebc-41d4-a406-b758f22b7cd6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'shape of a1 is{a1.shape}')\n",
        "print(f'shape of b1 is{b1.shape}')\n",
        "print(f'shape of c1 is{c1.shape}')\n",
        "print(f'shape of d1 is{d1.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9IJtMEaPV9B",
        "outputId": "4e1ee374-3a61-4c6f-cbb5-c0597c0152d2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of a1 istorch.Size([1, 6])\n",
            "shape of b1 istorch.Size([1, 6])\n",
            "shape of c1 istorch.Size([1, 6])\n",
            "shape of d1 istorch.Size([1, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(a == a1)\n",
        "print(b == b1)\n",
        "print(c == c1)\n",
        "print(d == d1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLXA8a6CPmUH",
        "outputId": "8bdc259c-a08f-4cd8-ed78-46251633439d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[True, True, True, True, True, True]])\n",
            "tensor([[True, True, True, True, True, True]])\n",
            "tensor([[True, True, True, True, True, True]])\n",
            "tensor([[True, True, True, True, True, True]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_qc6b0sSP8kG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJDMHJB7VoRE"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<h2><span style=\"color:blue\"> Task-1  Comments  </span></h2>\n",
        "</div>\n",
        "\n",
        "\n",
        "I did this becuase:\n",
        "* Abcd\n",
        "* Abcd\n",
        "\n",
        "\n",
        "I have observed following points:\n",
        "* Abcd\n",
        "* Abcd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2I3prjokdncH"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<h1><span style=\"color:green\"> Task-2  : Implement a Single-layer RNN  </span></h1>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3RyHNVPdncN"
      },
      "outputs": [],
      "source": [
        "class SimpleRNN(nn.Module):\n",
        "    \n",
        "    def __init__(self,input_dim, hidden_dim):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_dim  = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        \n",
        "        # Initialize W_x and W_h \n",
        "        # Bias terms are included in nn.Linear, so no need to initialize separate bias vector\n",
        "\n",
        "        self.W_x = nn.Linear(??) \n",
        "\n",
        "        self.W_h = nn.Linear(??) \n",
        "\n",
        "\n",
        "\n",
        "    def rnn_step(self, inp, hidden):\n",
        "        \n",
        "        \"\"\" Implementation of Single-layer RNN ONE Time Step\n",
        "            \n",
        "            Args:\n",
        "            \n",
        "                  inp   : input of shape( batch_size, input_dim)\n",
        "                  hidden: previoud hiedden state h_(t-1)\n",
        "            \n",
        "            \n",
        "            Returns:\n",
        "                     h_t : updated hidden state after ONE time step \n",
        "            \"\"\"\n",
        "\n",
        "        \n",
        "        prev_h = hidden\n",
        "        \n",
        "        h_t = None\n",
        "        \n",
        "        \n",
        "        # TODO: Implement one time step and update h\n",
        "\n",
        "        h_t = ??\n",
        "\n",
        "\n",
        "        return h_t\n",
        "\n",
        "\n",
        "    def forward(self, inp):\n",
        "        # Input should be of shape(seq_dim, batch_size, input_dim)\n",
        "\n",
        "        seq_dim, batch_size , _ = inp.shape\n",
        "\n",
        "        \n",
        "        # Initialize hidden state with zeros and shape(batch_size, hidden_dim)\n",
        "        # In case of batch gradient descent we have to maintain hidden vector \n",
        "        # for each training example in the batch\n",
        "        \n",
        "        h = ??\n",
        "\n",
        "        \n",
        "        # Loop through the whole sequence and update h_t at every time step\n",
        "        for x in inp:\n",
        "          # x is of shape (batch_size, input_dim)\n",
        "          h = self.rnn_step(x , h)\n",
        "        \n",
        "        return h \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNOokp0QVoRG"
      },
      "source": [
        "#### Output of RNN after T time steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWUBu8aofd9J"
      },
      "outputs": [],
      "source": [
        "# Testing RNN: This code should run without any error\n",
        "\n",
        "x = torch.randn(28, 1, 28) # (Seq_dim, batch_dim, inp_dim)\n",
        "\n",
        "rnn = SimpleRNN(28, 100)\n",
        "\n",
        "# Dimension of network parameters\n",
        "for p in rnn.parameters():\n",
        "    print(p.shape)\n",
        "\n",
        "    \n",
        "h_last_t = rnn(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQN7oa9-VoRH"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<h2><span style=\"color:blue\"> Task-2  Comments  </span></h2>\n",
        "</div>\n",
        "\n",
        "\n",
        "I did this becuase:\n",
        "* Abcd\n",
        "* Abcd\n",
        "\n",
        "\n",
        "I have observed following points:\n",
        "* Abcd\n",
        "* Abcd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCHZo4hX_KGF"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# LSTM\n",
        "If you read recent papers, you'll see that many people use a variant on the vanilla RNN called Long-Short Term Memory (LSTM) RNNs. Vanilla RNNs can be tough to train on long sequences because it suffers from vanishing/exploding gradient problem due to repeated matrix multiplication. LSTMs solve this problem by replacing the simple update rule of the vanilla RNN with a gating mechanism as follows.\n",
        "\n",
        "\n",
        "Similar to the vanilla RNN, at each time step we receive an input $x_t\\in\\mathbb{R}^D$ and the previous hidden state $h_{t-1}\\in\\mathbb{R}^H$; the LSTM also maintains an $H$-dimensional *cell state*, so we also receive the previous cell state $c_{t-1}\\in\\mathbb{R}^H$. The learnable parameters of the LSTM are an *input-to-hidden* matrix $W_x\\in\\mathbb{R}^{4H\\times D}$, a *hidden-to-hidden* matrix $W_h\\in\\mathbb{R}^{4H\\times H}$ and a *bias vector* $b\\in\\mathbb{R}^{4H}$.\n",
        "\n",
        "**Points to be noted**\n",
        "\n",
        "* *Cell State* is the internal state of LSTM. It provides a path for the flow of gradient which does not contain matrix multiplication to reduce the chances of vanishing/exploding gradient.\n",
        "\n",
        "* *Hidden State* is the output of the LSTM\n",
        "\n",
        "![lstm.png](attachment:lstm.png)\n",
        "<center> <a href=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/\" title=\"colah's blog\">\n",
        "Image Source</a></center>\n",
        "\n",
        "At each time step:\n",
        "\n",
        "**1.** An *activation vector* $a\\in\\mathbb{R}^{4H}$ is computed as $a=W_xx_t + W_hh_{t-1}+b$.\n",
        "\n",
        "**2.** Activation vector is partitioned into four vectors $a_i,a_f,a_o,a_c\\in\\mathbb{R}^H$ where $a_i$ consists of the first $H$ elements of $a$, $a_f$ is the next $H$ elements of $a$ and so on. \n",
        "\n",
        "**3.** We then compute the *input gate* $(i\\in\\mathbb{R}^H)$, *forget gate* $(f\\in\\mathbb{R}^H)$, *output gate* $(o\\in\\mathbb{R}^H)$ and *new candidate for $c_t$* $(\\tilde{c_t}\\in\\mathbb{R}^H)$ as\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "i = \\sigma(a_i) \\hspace{2pc}\n",
        "f = \\sigma(a_f) \\hspace{2pc}\n",
        "o = \\sigma(a_o) \\hspace{2pc}\n",
        "\\tilde{c_t} = \\tanh(a_c)\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "where $\\sigma$ is the sigmoid function and $\\tanh$ is the hyperbolic tangent, both applied element-wise.\n",
        "\n",
        "\n",
        "  * *new candidate vector* ($\\tilde{c_t}$) provides candidate values for new cell state ($c_t$)\n",
        "  \n",
        "  * *input gate* ($i$) determines the positions where data should be injected from  $\\tilde{c_t}$ to new cell state ($c_t$)\n",
        "\n",
        "  * *forget gate* ($f$) removes the useless data from previous cell state $c_{t-1}$\n",
        "\n",
        "  * *output gate* ($o$) determines the data to pass from current cell state $c_t$ to current hidden state $h_t$\n",
        "  \n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "**4.** Finally, we update the next cell state $c_t$ and next hidden state $h_t$ as follows\n",
        "\n",
        "$$\n",
        "c_{t} = f\\odot c_{t-1} + i\\odot \\tilde{c_t} \\hspace{4pc}\n",
        "h_t = o\\odot\\tanh(c_t)\n",
        "$$\n",
        "\n",
        "where $\\odot$ is the element-wise (Hadamard) product of vectors.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAzF_bU__KHB",
        "tags": [
          "pdf-inline"
        ]
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "<h1><span style=\"color:red\"> Question  </span></h1>\n",
        "</div>\n",
        "\n",
        "Recall that in an LSTM the input gate $i$, forget gate $f$, and output gate $o$ are all outputs of a sigmoid function. Why don't we use the ReLU activation function instead of sigmoid to compute these values? Explain.\n",
        "\n",
        "**Your Answer:** \n",
        "\n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-PABcjOAx0u"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<h1><span style=\"color:green\"> Task-3 : Implement a Single-layer LSTM  </span></h1>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Cf6ozWaC-2g"
      },
      "outputs": [],
      "source": [
        "class SimpleLSTM(nn.Module):\n",
        "    \n",
        "    def __init__(self,input_dim, hidden_dim):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        \n",
        "        self.input_dim  = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        \n",
        "        #TODO: Initialize W_x and W_h\n",
        "        # Bias terms are included in nn.Linear, so no need to initialize separate bias vector\n",
        "        \n",
        "        self.W_x = nn.Linear(??)\n",
        "        self.W_h = nn.Linear(??)\n",
        "\n",
        "\n",
        "\n",
        "    def lstm_step(self, inp, prev_hidden_cell):\n",
        "        \"\"\" Implementation of Single-layer LSTM ONE Time Step\n",
        "            \n",
        "            Args:\n",
        "                    inp      : input of shape(batch_size, input_dim)\n",
        "             prev_hidden_cell: tuple (previous_hidden_state, previous_cell_state)\n",
        "            \n",
        "            \n",
        "            Returns:\n",
        "                    Updated hidden state and cell state \n",
        "        \"\"\"\n",
        "\n",
        "        \n",
        "        \n",
        "        h_prev , c_prev = prev_hidden_cell\n",
        "        \n",
        "        \n",
        "        # The activation vector\n",
        "        activation = ??\n",
        "        \n",
        "        \n",
        "        # The activation is split into four parts\n",
        "        ai, af, ac, ao = activation.chunk(4, 1)\n",
        "\n",
        "        \n",
        "        updated_h, updated_c = None, None\n",
        "      \n",
        "    \n",
        "        # TODO: Implement the gates of lstm and update hidden state and cell state\n",
        "\n",
        "        in_gate     = ??\n",
        "        forget_gate = ??\n",
        "        cell_gate   = ??\n",
        "        out_gate    = ??\n",
        "\n",
        "        \n",
        "        updated_c  = ??\n",
        "        updated_h  = ??\n",
        "        \n",
        "\n",
        "\n",
        "        return updated_h, updated_c\n",
        "\n",
        "\n",
        "    def forward(self, inp):\n",
        "        \n",
        "        # input shape (seq_dim, batch_size, input_dim)\n",
        "\n",
        "        # TODO: initialize hidden and cell state and loop through sequence\n",
        "\n",
        "        # Initialize hidden state with zeros (batch_size, hidden_dim)\n",
        "        h = ??\n",
        "        \n",
        "        # Initialize cell state with zeros (batch_size, hidden_dim)\n",
        "        c = ??\n",
        "        \n",
        "        \n",
        "        # Loop through the whole sequence and update h_t and c_t at every time step\n",
        "        for x in inp:\n",
        "            \n",
        "           # shape of x is (batch_size, input_dim )\n",
        "        \n",
        "           h, c = self.lstm_step( x, (h, c) )\n",
        "        \n",
        "        return h \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8aoOVqkHEpX"
      },
      "source": [
        "#### Output of LSTM Cell after T time steps\n",
        "The final updated hidden state is the output of LSTM. After filtering the data through gates, the final hidden state can provide us with the relevant indormation for our task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfKB5rpg7yN6"
      },
      "outputs": [],
      "source": [
        "# Testing LSTM: The code should run with any erros\n",
        "\n",
        "#test input of shape(Sequence_len, Batch_size , Input_dim)\n",
        "x = torch.randn(28, 1 ,28)\n",
        "\n",
        "m = SimpleLSTM(28, 100)\n",
        "\n",
        "out = m(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AepgywaAVoRK"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<h2><span style=\"color:blue\"> Task-3  Comments  </span></h2>\n",
        "</div>\n",
        "\n",
        "\n",
        "I did this becuase:\n",
        "* Abcd\n",
        "* Abcd\n",
        "\n",
        "\n",
        "I have observed following points:\n",
        "* Abcd\n",
        "* Abcd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "9-K_Hi3oAxzG"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<h1><span style=\"color:orange\"> Image Classification with LSTM  </span></h1>\n",
        "</div>\n",
        "\n",
        "In this section, you  will use an LSTM network for MNIST image classification. We will use **many-to-one** scenario for this task. Refer to following figure to understand *many-to-one* LSTM.\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "![lstm_shapes.png](attachment:lstm_shapes.png)\n",
        "<center> <a href=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/\" title=\"Andrej Karpathy's blog\">\n",
        "Image Source</a></center>\n",
        "\n",
        "\n",
        "### Loading MNIST Train Dataset\n",
        "MNIST contains 70,000 images of handwritten digits: 60,000 for training and 10,000 for testing. The images are grayscale, 28x28 pixels, and centered to reduce preprocessing and get started quicker."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqoBq5UtAxzi"
      },
      "outputs": [],
      "source": [
        "train_dataset = dsets.MNIST(root='./data', \n",
        "                            train=True, \n",
        "                            transform=transforms.ToTensor(),\n",
        "                            download=False)\n",
        "\n",
        "test_dataset = dsets.MNIST(root='./data', \n",
        "                           train=False, \n",
        "                           transform=transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0Pc-hQ7Axzz"
      },
      "outputs": [],
      "source": [
        "print('Train Data   : ',train_dataset.data.size())\n",
        "print('Train Labels : ',train_dataset.targets.size())\n",
        "print('Test Data    : ',test_dataset.data.size())\n",
        "print('Test Labels  : ',test_dataset.targets.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a-YTEreqLNn"
      },
      "source": [
        "### Make Dataset Iterable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x712Bsl4qLNp"
      },
      "outputs": [],
      "source": [
        "batch_size = 100\n",
        "n_iters = 3000\n",
        "\n",
        "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eWyFr9LMtXF"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<h1><span style=\"color:green\"> Task-4 : Plot Images  </span></h1>\n",
        "</div>\n",
        "\n",
        "Plot 4 random images using plt.imshow  and cmap = 'gray' in a 2x2 grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ShahgdXHxwZ"
      },
      "outputs": [],
      "source": [
        "# TODO: Plot MNIST Images in 2x2 grid\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gB0MoKWxVoRN"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<h2><span style=\"color:blue\"> Task-4  Comments  </span></h2>\n",
        "</div>\n",
        "\n",
        "\n",
        "I did this becuase:\n",
        "* Abcd\n",
        "* Abcd\n",
        "\n",
        "\n",
        "I have observed following points:\n",
        "* Abcd\n",
        "* Abcd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZkb9ZJKVoRN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIT2lUlVVoRO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZobVz83YVoRO"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<h1><span style=\"color:green\"> Task-5 : Build LSTM network for MNIST image Classification  </span></h1>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HMouA8O9p93"
      },
      "source": [
        "### Initialize an LSTM Model Using Pytorch's nn.LSTM() Class\n",
        "Create an  LSTM model for classification of MNIST images. Follow the structure given below;\n",
        "\n",
        "1. One LSTM Cell\n",
        "2. One Linear Fully-Connected Layer\n",
        "\n",
        "\n",
        "Read Pytorch [documentation]( https://pytorch.org/docs/stable/nn.html?highlight=lstm#torch.nn.LSTM) to learn about **nn.LSTM()**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDzRz-IPAx0w"
      },
      "outputs": [],
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
        "        \n",
        "        super(LSTMModel, self).__init__()\n",
        "        \n",
        "        \n",
        "        # Hidden dimensions: Number of features in hidden/cell state\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        \n",
        "        \n",
        "        # Number of LSTM cells/layers \n",
        "        self.layer_dim = layer_dim\n",
        "\n",
        "        \n",
        "        \n",
        "        # Declaring attributes of model for LSTM cell and read-out linear fully-connected layer\n",
        "        self.lstm = None\n",
        "        self.fc   = None\n",
        "\n",
        "        \n",
        "        \n",
        "        # TODO: Intialize LSTM and linear layer\n",
        "             \n",
        "        \n",
        "        # Initialize LSTM Cell/s\n",
        "        self.lstm = nn.LSTM(????,  batch_first=True)\n",
        "        \n",
        "        \n",
        "        \n",
        "        # Readout fully-connected layer. It takes hidden state from last time step and converts this hidden state to logits\n",
        "        self.fc = nn.Linear(?????)                                     \n",
        "        \n",
        "\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        # Assuming batch_first=True\n",
        "        # x       : input consists of a sequence or a batch of sequences.   shape: (batch, seq_len, features)\n",
        "        #         : batch = number of sequences in one batch ,      seq_len = number of time steps       ,  features= number of features in one part sequence at each time step\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        # Everytime when model is called, intial hidden state and cell state would be initialized with zeros\n",
        "        \n",
        "        # Initialize hidden state with zeros\n",
        "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)     # shape: (num_layers * num_directions, batch, hidden_size)\n",
        "        # Initialize cell state with zeros\n",
        "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)     # shape: (num_layers * num_directions, batch, hidden_size)\n",
        "        \n",
        "        \n",
        "        # x       : input consists of a sequence of batch of sequences.   shape: (batch, seq_len, features)                         Assuming batch_first=True\n",
        "        # out     : tensor containing hidden states from all time steps.  shape: (batch, seq_len,  num_directions * hidden_size)    Assuming batch_first=True\n",
        "        # (hn,cn) : hidden state and cell state after last time-step.     shape: (num_layers * num_directions, batch, hidden_size)\n",
        "        out, (hn, cn) = self.lstm(??????)\n",
        "        \n",
        "        \n",
        "        # Take hidden state from last time step and convert it to logits using fully-connected layer\n",
        "        out = self.fc(out[??????]) \n",
        "        \n",
        "        \n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHofntvvAx06"
      },
      "source": [
        "### Instantiate Model Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RK6PB1eFAx08"
      },
      "outputs": [],
      "source": [
        "input_dim  = 28      # Number of elements in each part of sequence. \n",
        "hidden_dim = 100     # Number of elements in hidden/cell state\n",
        "layer_dim  = 1       # Number of LSTM Cells\n",
        "output_dim = 10      # Number of classes,  There are 10 classes in MNIST dataset (Digits: 0,1,2,...9)\n",
        "\n",
        "\n",
        "\n",
        "model = LSTMModel( ????????????)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwuxsDpxAx1G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmJWpzK-Ax1R"
      },
      "source": [
        "### Instantiate Loss Class\n",
        "We are going to use **Cross Entropy Loss** for this classifcation problem.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVX2NLKjAx1T"
      },
      "outputs": [],
      "source": [
        "criterion = nn.??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n25l-VXfAx1f"
      },
      "source": [
        "### Instantiate Optimizer Class\n",
        "\n",
        "\n",
        "- Simplified equation\n",
        "    - $ \\boldsymbol{\\theta} $ = $\\boldsymbol{\\theta} - \\eta \\cdot \\nabla_{\\boldsymbol{\\theta}} $\n",
        "        - $ \\boldsymbol{\\theta} $: parameters (learnable variables/parameters)\n",
        "        - $\\eta $: learning rate (how fast we want to learn)\n",
        "        - $\\nabla_{\\boldsymbol{\\theta}}$: parameters' gradients\n",
        "- Even simplier equation\n",
        "    - `parameters = parameters - learning_rate * parameters_gradients`\n",
        "    - **At every iteration, we update our model's parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjbo0uYXAx1h"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.1\n",
        "\n",
        "optimizer = torch.optim.SGD(?????)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hThFQTpWAx1p"
      },
      "source": [
        "### Parameters In-Depth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWziDDg7Ax1s"
      },
      "outputs": [],
      "source": [
        "len(list(model.parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70Vc8-KWAx13"
      },
      "outputs": [],
      "source": [
        "for i in range(len(list(model.parameters()))):\n",
        "    print(list(model.parameters())[i].size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9qisKEzAx2C"
      },
      "source": [
        "### Understanding LSTM Training\n",
        "\n",
        "Firstly lets see how image passes through LSTM and loss is calculate.\n",
        "\n",
        "1. Firstly, we have converted 28x28 image into sequence of 28 1x28 image strips.\n",
        "2. At each time step, we feed LSTM 1x28 image strip and update hidden state and cell state.\n",
        "3. After passing all the 28 1x28 sequence of image parts, we take the final hidden state and pass it as input to a fully connected layer.\n",
        "4. The fully-connected layer outpus, 10 logits(unnormalized scores) for iamge classes.\n",
        "5. We use softmax to normalize the scores and calculate Cross Entropy Loss\n",
        "\n",
        "In case of backward pass, gradient flows from final time step to initial time step of LSTM and gradients of parameters are added together.\n",
        "\n",
        "\n",
        "\n",
        "### Train Model\n",
        "- Process \n",
        "    1. Take one sequence or batch of sequences\n",
        "    2. Clear gradient buffers\n",
        "    3. Get output by forward-passing input through model/network\n",
        "    4. Compute **cross-entropy** loss using labels and output of network\n",
        "    5. Get gradients w.r.t. parameters\n",
        "    6. Update parameters using gradients\n",
        "        - `parameters = parameters - learning_rate * parameters_gradients`\n",
        "    7. REPEAT\n",
        "\n",
        "In this homework, we will feed an LSTM cell an entire MNIST image in the form of a sequence of 28 rows and then classify the image. Data can be viewed as a set of $N$ examples $\\{(\\mathbf{x_i},y_i)\\}_{i=1}^{N}$. In each pair $(\\mathbf{x_i},y_i)$, $\\mathbf{x_i} = \\langle \\mathbf{x_{i,1}}, \\mathbf{x_{i,2}},\\dots, \\mathbf{x_{i,28}}\\rangle$ is a sequence of 28 vectors, each of dimension $(1,28)$.<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1l1iBghdVoRR"
      },
      "source": [
        "### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzUkcxPqAx2D"
      },
      "outputs": [],
      "source": [
        "# Number of time steps or Number of constituents of one sequence\n",
        "seq_len = 28  \n",
        "\n",
        "\n",
        "\n",
        "iteration = 0\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        \n",
        "        # Shape of images = (batch_size, num_channels, 28, 28)\n",
        "        # Shape of images = (batch_size, 1           , 28, 28)\n",
        "        \n",
        "        # Reshape batch of images into batch of sequences,    \n",
        "        inputs = images.view(-1, seq_len, input_dim)  # shape: (batch, seq_len, input_features)\n",
        "        \n",
        "        \n",
        "        # Clear gradients w.r.t. parameters\n",
        "        ??\n",
        "        \n",
        "        \n",
        "        \n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(??)\n",
        "        \n",
        "        \n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(????)\n",
        "        \n",
        "        \n",
        "        # Getting gradients w.r.t. parameters\n",
        "        ????\n",
        "        \n",
        "        \n",
        "        # Updating parameters\n",
        "        ????\n",
        "        \n",
        "        \n",
        "        \n",
        "        iteration += 1\n",
        "        \n",
        "        \n",
        "        # Test Accuracy on Test Data\n",
        "        if iteration % 500 == 0:\n",
        "            with torch.no_grad():   #  We do not want to add following operations in computation graph.\n",
        "                \n",
        "                \n",
        "                correct = 0\n",
        "                total = 0\n",
        "\n",
        "\n",
        "                # Iterate through test dataset\n",
        "                for images, labels in test_loader:\n",
        "\n",
        "                    # Shape of images = (batch_size, num_channels, 28, 28)\n",
        "                    # Shape of images = (batch_size, 1           , 28, 28)\n",
        "                    \n",
        "                    # Reshape batch of images into batch of sequences\n",
        "                    inputs = images.view(-1, seq_len, input_dim)   # shape: (batch, seq_len, input_features)\n",
        "        \n",
        "        \n",
        "\n",
        "                    # Forward pass only to get logits/output\n",
        "                    outputs = model(???)\n",
        "\n",
        "                    # Get predictions from outputs\n",
        "                    predicted = ??\n",
        "\n",
        "                    \n",
        "                    # Total number of labels\n",
        "                    total += labels.size(0)\n",
        "\n",
        "                    \n",
        "                    # Total correct predictions\n",
        "                    correct += (predicted == labels).sum()\n",
        "\n",
        "                accuracy = 100 * correct.item() / total\n",
        "\n",
        "                # Print Loss\n",
        "                print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iteration, loss.item(), accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGFN_-b1VODI"
      },
      "source": [
        "### LSTM Network with Multiple Cells/Layers\n",
        "In the above example, we have used LSTM with only one layer but it is possible to stack multiple LSTM cells/layers over each other. Each LSTM cell/layer has its own set of parameters as well as hidden and cell states. The output of first LSTM cell/layer(hidden state) is fed as input to the next LSTM cell/layer. \n",
        "\n",
        "\n",
        "* Increasing the no of layers allow LSTM to learn more complex patterns. But it can overfit\n",
        "\n",
        "* You have to maintain hidden state and cell state for each layer and each layer comes with a lot of additional network parmateters\n",
        "\n",
        "* You will only come across maximum of 3 to 4 stacked layers/cells of LSTM. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl1UesEJWjAf"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "<h1><span style=\"color:red\"> Question  </span></h1>\n",
        "</div>\n",
        "\n",
        "\n",
        "#### LSTM with Multiple Cells/Layers\n",
        "Use pytorch nn.LSTM class to initialize LSTM model with 2 cell/layers and then 3 cell/layers. Comment on the results.\n",
        "\n",
        "**HINT**: You just have to change the layer_dim\n",
        "\n",
        "**Comments**: \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9YvZw67VoRR"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "<h1><span style=\"color:red\"> Question  </span></h1>\n",
        "</div>\n",
        "\n",
        "\n",
        "What does **.detach()** do in Pytorch? Describe **'Backward'** propagation in single-cell LSTM network.\n",
        "\n",
        "**Answer**: \n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFTexsAOD5Z-"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<h2><span style=\"color:blue\"> Task-5  Comments  </span></h2>\n",
        "</div>\n",
        "\n",
        "\n",
        "I did this becuase:\n",
        "* Abcd\n",
        "* Abcd\n",
        "\n",
        "\n",
        "I have observed following points:\n",
        "* Abcd\n",
        "* Abcd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLTrRWuOVoRS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snT-Im5lVoRS"
      },
      "source": [
        "### Convert .IPYNB to .HTML "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGSmpCCUVoRS",
        "outputId": "c0441c02-7d2f-4014-cf05-f31bf706ed11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NbConvertApp] Converting notebook LSTM_Homework_StarterCodeNew.ipynb to html\n",
            "[NbConvertApp] Writing 696890 bytes to LSTM_Homework_StarterCodeNew.html\n"
          ]
        }
      ],
      "source": [
        "import os \n",
        "cwd = os.getcwd()\n",
        "os.chdir(cwd)\n",
        "\n",
        "!jupyter nbconvert LSTM_Homework_StarterCodeNew.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYIqjOa3VoRT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}